# spark-submit.conf
spark.master spark://spark-master:7077
spark.driver.extraJavaOptions -Dfile.encoding=UTF-8 -Dlog4j.configuration=/opt/spark/conf/log4j2.properties
spark.executor.extraJavaOptions -Dfile.encoding=UTF-8 -Dlog4j.configuration=/opt/spark/conf/log4j2.properties
spark.app.config /opt/config/application.conf
spark.driver.memory 8g
spark.executor.memory 14g
spark.executor.cores 4
spark.executor.instances 3
spark.executor.memoryOverhead 3072
spark.memory.offHeap.enabled false
spark.serializer org.apache.spark.serializer.KryoSerializer
spark.kryoserializer.buffer 64m
spark.kryoserializer.buffer.max 1024m
spark.local.dir /opt/spark/local
spark.sql.adaptive.enabled true
spark.sql.adaptive.coalescePartitions.enabled true
spark.sql.adaptive.advisoryPartitionSizeInBytes 64MB
spark.sql.adaptive.skewJoin.enabled true
spark.sql.adaptive.skewJoin.skewedPartitionFactor 5
spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes 256MB
# NOTE: La réduction des partitions de brassage peut entraîner un déséquilibre
# des données ou des brassages lents pour les grands ensembles de données.
# Pour les grands ensembles de données, une surveillance de la taille des
# partitions et de la durée des tâches après ce changement est nécessaire.
# Si des problèmes de performance sont constatés, L'augmentation de 
# spark.sql.shuffle.partitions permettrait de résoudrele problème.
spark.sql.shuffle.partitions 192
spark.default.parallelism 192
spark.network.timeout 600s
spark.executor.heartbeatInterval 30s
spark.shuffle.compress true
spark.shuffle.spill.compress true
spark.sql.files.maxRecordsPerFile 2000000
spark.sql.autoBroadcastJoinThreshold 50m
spark.sql.join.preferSortMergeJoin true
spark.sql.inMemoryColumnarStorage.compressed true
spark.sql.inMemoryColumnarStorage.batchSize 20000
