#!/usr/bin/env bash
set -e  # Stop on first error

# =========================================================
# Script de build + lancement du cluster Spark + job
# =========================================================

BUILD=false

# === Parsing des arguments ===
while [[ $# -gt 0 ]]; do
  case "$1" in
    --build)
    BUILD=true
    ;;
    *)
    echo "âš ï¸  Argument inconnu : $1"
    ;;
  esac
  shift
done

ASSEMBLY_JAR="target/scala-2.12/flight-assembly.jar"

# =========================================================
# Ã‰tape 0 : VÃ©rification de la prÃ©sence et rapatriement du dataset
# =========================================================
echo "ğŸ“ VÃ©rification du dataset..."
./get-data.sh

# =========================================================
# Ã‰tape 1 : Compilation du projet Scala (si build, fat JAR)
# =========================================================
if [ "$BUILD" = true ]; then
  echo "ğŸ”§ Compilation du projet Scala avec sbt-assembly..."

  # VÃ©rifie que sbt est installÃ©
  if ! command -v sbt &>/dev/null; then
      echo "âŒ Erreur : 'sbt' n'est pas installÃ© sur la machine hÃ´te."
      exit 1
  fi

  # Nettoyage et crÃ©ation du jar assemblÃ©
  if sbt clean assembly; then
      echo "âœ… Compilation et assembly rÃ©ussis."
  else
      echo "âŒ Ã‰chec de la compilation Scala."
      exit 1
  fi

  # VÃ©rifie que le JAR assemblÃ© existe
  if [ ! -f "$ASSEMBLY_JAR" ]; then
      echo "âŒ Fichier $ASSEMBLY_JAR introuvable aprÃ¨s l'assembly."
      exit 1
  fi
fi

# =========================================================
# Ã‰tape 2 : (Re)dÃ©marrage du cluster Spark via Docker
# =========================================================
echo "ğŸ§¹ ArrÃªt de tout cluster Spark existant..."
docker rm -f spark-submit spark-worker spark-master >/dev/null 2>&1 || true

echo "ğŸš€ DÃ©marrage du cluster Spark..."
docker compose up -d

echo "â³ Attente de la disponibilitÃ© du Spark Master..."
sleep 5

# =========================================================
# Ã‰tape 3 : Copie du JAR dans le conteneur spark-submit
# =========================================================
echo "ğŸ“¦ Copie du jar assemblÃ© dans le conteneur..."
docker cp "$ASSEMBLY_JAR" spark-submit:/app/flight-assembly.jar

# =========================================================
# Ã‰tape 4 : PrÃ©paration du script spark-submit.sh
# =========================================================
echo "âš™ï¸  PrÃ©paration du script spark-submit.sh..."
docker exec spark-submit dos2unix /app/spark-submit.sh >/dev/null 2>&1 || true
docker exec spark-submit chmod +x /app/spark-submit.sh

# =========================================================
# Ã‰tape 5 : Soumission du job Spark
# =========================================================
echo "ğŸš€ Soumission du job Spark..."
docker exec spark-submit /app/spark-submit.sh

echo ""
echo "ğŸ“œ Logs du conteneur spark-submit :"
docker logs spark-submit

echo ""
echo "âœ… Job Spark terminÃ© avec succÃ¨s."