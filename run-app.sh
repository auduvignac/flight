#!/usr/bin/env bash
set -e  # Stop on first error

# =========================================================
# Script de build + lancement du cluster Spark + job
# =========================================================

# === ParamÃ¨tres par dÃ©faut ===
BUILD=false
LOCAL=true
RESET=false
STAGE="all"
DATA_DIR_PATH=${DATA_PATH:-./data}

# === Parsing des arguments ===
while [[ $# -gt 0 ]]; do
  case "$1" in
    --build)
    BUILD=true
    ;;
    --local)
    LOCAL=true
    ;;
    --reset)
    RESET=true
    ;;
    --stage=*)
    STAGE="${1#*=}"
    ;;
    *)
    echo "âš ï¸  Argument inconnu : $1"
    ;;
  esac
  shift
done

if [ "$LOCAL" = true ]; then
  if [ ! -d "$DATA_DIR_PATH" ] || [ -z "$(ls -A $DATA_DIR_PATH)" ]; then
    echo "[run-app] Dataset manquant. ArrÃªt."
    exit 1
  fi
  echo "[run-app] Mode local dÃ©tectÃ© : dataset prÃ©sent, exÃ©cution Spark directe."
  ./spark-submit.sh "$STAGE"
fi

ASSEMBLY_JAR="target/scala-2.12/flight-assembly.jar"

# =========================================================
# Ã‰tape 0 : VÃ©rification de la prÃ©sence et rapatriement du dataset
# =========================================================
echo "ðŸ“ VÃ©rification du dataset..."
./get-data.sh

if [ $? -ne 0 ]; then
  echo "âŒ Erreur lors du tÃ©lÃ©chargement du dataset."
  exit 1
fi

# =========================================================
# Ã‰tape 1 : Compilation du projet Scala (si build, fat JAR)
# =========================================================
if [ "$BUILD" = true ]; then
  echo "ðŸ”§ Compilation du projet Scala avec sbt-assembly..."

  # VÃ©rifie que sbt est installÃ©
  if ! command -v sbt &>/dev/null; then
      echo "âŒ Erreur : 'sbt' n'est pas installÃ© sur la machine hÃ´te."
      exit 1
  fi

  # Nettoyage et crÃ©ation du jar assemblÃ©
  if sbt clean assembly; then
      echo "âœ… Compilation et assembly rÃ©ussis."
  else
      echo "âŒ Ã‰chec de la compilation Scala."
      exit 1
  fi

  # VÃ©rifie que le JAR assemblÃ© existe
  if [ ! -f "$ASSEMBLY_JAR" ]; then
      echo "âŒ Fichier $ASSEMBLY_JAR introuvable aprÃ¨s l'assembly."
      exit 1
  fi
fi

# =========================================================
# Ã‰tape 2 : (Re)dÃ©marrage du cluster Spark via Docker
# =========================================================
echo "ðŸ§¹ ArrÃªt de tout cluster Spark existant..."
docker rm -f spark-submit spark-worker spark-master >/dev/null 2>&1 || true

echo " CrÃ©ation du rÃ©pertoire local de shuffle..."
mkdir -p ./spark-local   # +++ support shuffle local

echo "ðŸš€ DÃ©marrage du cluster Spark..."
docker compose up -d

echo "â³ Attente de la disponibilitÃ© du Spark Master..."
for i in {1..15}; do
  if docker logs spark-master 2>&1 | grep -q "Starting Spark master"; then
    break
  fi
  echo "â³ Spark master en prÃ©paration..."
  sleep 2
done

if [ "$RESET" = true ]; then
  echo "ðŸ§¹ Suppression du rÃ©pertoire delta (via conteneur root)..."
  # Attente du conteneur worker
  worker_found=false
  for i in {1..10}; do
    if docker ps | grep -q spark-worker; then
      worker_found=true
      # VÃ©rifier l'accessibilitÃ© du rÃ©pertoire delta
      if docker compose exec -u root spark-worker bash -c "[ -d /app/delta ]"; then
        if docker compose exec -u root spark-worker bash -c "[ -w /app/delta ]"; then
          docker compose exec -u root spark-worker bash -c "rm -rf /app/delta/* || true"
          echo "âœ… RÃ©pertoire delta nettoyÃ©."
        else
          echo "âŒ Le rÃ©pertoire /app/delta existe mais n'est pas accessible en Ã©criture dans le conteneur spark-worker."
        fi
      else
        echo "âŒ Le rÃ©pertoire /app/delta n'existe pas dans le conteneur spark-worker."
      fi
      break
    fi
    echo "â³ Attente du dÃ©marrage du spark-worker..."
    sleep 2
  done
  if [ "$worker_found" = false ]; then
    echo "âŒ Le conteneur spark-worker n'est pas en cours d'exÃ©cution. Impossible de rÃ©initialiser le rÃ©pertoire delta."
  fi
fi

# =========================================================
# Ã‰tape 3 : Copie du JAR dans le conteneur spark-submit
# =========================================================
echo "ðŸ“¦ Copie du jar assemblÃ© dans le conteneur..."
docker cp "$ASSEMBLY_JAR" spark-submit:/app/flight-assembly.jar

# =========================================================
# Ã‰tape 4 : PrÃ©paration du script spark-submit.sh
# =========================================================
echo "âš™ï¸  PrÃ©paration du script spark-submit.sh..."
docker exec spark-submit dos2unix /app/spark-submit.sh >/dev/null 2>&1 || true

# =========================================================
# Ã‰tape 5 : Soumission du job Spark
# =========================================================
echo "ðŸš€ Soumission du job Spark..."
echo "----------------------------------------------"
echo "Build : $BUILD"
echo "Stage : $STAGE"
echo "----------------------------------------------"
docker exec spark-submit /app/spark-submit.sh "$STAGE"

echo ""
echo "ðŸ“œ Logs du conteneur spark-submit :"
docker logs spark-submit

echo ""
echo "âœ… Job Spark terminÃ© avec succÃ¨s."